
# Segmentation of ventricular in the Myocardium 

## Overview
This project involves the training and evaluation of deep learning
models, specifically U-Net models, for image segmentation tasks. It
includes three main scripts: `UnetModels.py`,
`model_training_and_eval.py`, and `grid_training.py`. In addition it
needs preprocessed pickle files of the dataset generated by
`get_images_and_masks.py`, created by C. Cappelen and slightly
modified by T. R. Choat. Modifications in this fork by T. Eftestøl.


### File Descriptions
- **myosegm.ipynb**: Jupyter notebook demonstrating loading data and
  segmenting images.  Requires pretrained models
  [best_model_multires.h5](https://github.com/OttoNessaLjosdal/ELE690-2023_Myocardium_Segmentation/blob/main/best_model_multires.h5)
  and
  [best_model_residual.h5](https://github.com/OttoNessaLjosdal/ELE690-2023_Myocardium_Segmentation/blob/main/best_model_residual.h5)
  from the GitHub repository [ELE690-2023_Myocardium_Segmentation](https://github.com/OttoNessaLjosdal/ELE690-2023_Myocardium_Segmentation).
- **UnetModels.py**: Contains the definitions of various U-Net architectures for image segmentation. Standard, Residual(Modified) and MultiRes Model.
- **model_training_and_eval.py**: Handles the training and evaluation of models. Includes functions for data preprocessing, model training, and performance evaluation, as well as callback functions, loss functions and more.
- **grid_training.py**: Orchestrates the training process, potentially
  over various configurations or hyperparameters.


## Prerequisites
- Python 3.10
- tensorflow 2.10.0
- NumPy, Matplotlib, OpenCV (cv2), Scikit-Learn, and other standard data processing libraries.

## Setup
1. Ensure all prerequisites are installed. An extended enviroment (GPU-supported) is listed in the requirements.txt file. Usage: "pip install -r requirements.txt"
2. Place the scripts in a common directory.
3. For a non-GPU environment, use requirements_cpu.txt. Som code,
   allocating GPU resources will need some modifications.

## Usage
1. Choose your U-Net model architecture by browsing `UnetModels.py`.
2. Check `model_training_and_eval.py` to set up your training and evaluation pipeline. This may include data loading, augmentation, and defining metrics.
3. Run `grid_training.py` to start the training process. This script will need to be configured based on your specific dataset and model requirements.

## Notes
- The exact usage and functionality might differ based on the specific implementation details within each script.
- Note that `get_images_and_masks.py` is dependant on two support scripts `orgim_scr.py` and `CropHeart.py`, as well as access to CardioMiner.
- Ensure to configure the environment settings (like CUDA_VISIBLE_DEVICES) in `grid_training.py` based on your hardware setup.
- Make sure to activate the custom environments for cuda and cudnn if the grid training is supposed to run on server GPUs. The experiements in this project were run with:
    - uenv cuda-11.4
    - uenv cudnn-11.x-8.2.1
- When executing the project files from a terminal, it would be initiated in this order:
    "
    ssh go6
    source .venv/mcpy310/bin/activate
    uenv cuda-11.4
    uenv cudnn-11.x-8.2.1
    cd /Project/Folder
    python3 grid_training.py
    "
- `get_images_and_masks.py` could use a rework to fit better with ImageDataGenerator and move to the use of Pandas dataframe instead of simple arrays. 
